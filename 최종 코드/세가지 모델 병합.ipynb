{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fe86ee-a733-4f99-82fc-55bfbee491d5",
   "metadata": {},
   "source": [
    "# 피클 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543e97c-b7e3-4452-a28b-1b6ada34c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./최종 파일/lsvc_model.pkl', 'rb') as f:\n",
    "    lsvc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9f5e4-1326-4b72-9f44-32729eaf1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./최종 파일/lsvc_tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8d4e3-d223-4440-b028-7dddd6ac47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_mapping.pkl', 'rb') as f:\n",
    "    label_mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe4947-5013-4499-bc05-e07ce549bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "lstm_model = load_model('best_model.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91eb904-b65e-4749-80cc-b41065195e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "with open('./최종 파일/lstm_tokenizer2.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa16c0-581d-4f21-954d-2d14c13621f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cosine_tfidf.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38009e00-f51c-4b70-a14d-290177fa24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cosine_dict.pkl', 'rb') as f:\n",
    "    cosine_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdeeb2d-bd5d-45e8-a7a9-93b6f0296a43",
   "metadata": {},
   "source": [
    "# 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548e06f-ea2d-4895-8bcc-18a6e9499337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0791a-cca7-4314-a90f-7cf3d4f93711",
   "metadata": {},
   "source": [
    "# 세 모델 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f5f52-cfba-4b44-bcf1-c94006bae44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_ensemble_predict(description):\n",
    "    ## 입력값 전처리\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.append('x')\n",
    "    stop_words.append('w')\n",
    "    \n",
    "    # 텍스트 전처리: 소문자 변환, 토큰화, 불용어 제거\n",
    "    tokens = word_tokenize(description.lower())\n",
    "    tagged_tokens = nltk.pos_tag(tokens)  # 단어 토큰에 품사 태깅 추가\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_tokens = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        if (tag.startswith('NN') or tag.startswith('VB')) and word not in stop_words:  # 명사 또는 동사인 경우\n",
    "            lemma = lemmatizer.lemmatize(word, pos='n' if tag.startswith('NN') else 'v')\n",
    "            filtered_tokens.append(lemma)\n",
    "        elif word.isalpha() and word not in stop_words:\n",
    "            filtered_tokens.append(word)\n",
    "    preprocessed_description = [' '.join(filtered_tokens)]\n",
    "\n",
    "    ## LSVC 모델 적용\n",
    "    description_tfidf_vec = tfidf_vec.transform(preprocessed_description)\n",
    "    decision_values = lsvc.decision_function(description_tfidf_vec)\n",
    "\n",
    "    lsvc_top3_list = []\n",
    "    proba_list = decision_values.argsort().flatten().tolist()[::-1][:3]\n",
    "    for i in proba_list:\n",
    "        for k, v in label_mapping.items():\n",
    "          if k == i:\n",
    "            lsvc_top3_list.append(v)\n",
    "\n",
    "    #w1 = 1\n",
    "    lsvc_top3_dict = {lsvc_top3_list[0]:3, lsvc_top3_list[1]:2, lsvc_top3_list[2]:1}\n",
    "    #lsvc_top3_dict_w = { k : v*w1 for k, v in lsvc_top3_dict.items() }\n",
    "    \n",
    "    ## LSTM 모델 적용\n",
    "    description_encoded = tokenizer.texts_to_sequences(preprocessed_description)\n",
    "    description_padded = pad_sequences(description_encoded, maxlen=800)\n",
    "\n",
    "    des_predict = lstm_model.predict(description_padded)\n",
    "\n",
    "    lstm_top3_list = []\n",
    "    proba_list = des_predict.argsort().flatten().tolist()[::-1][:3]\n",
    "    for i in proba_list:\n",
    "        for k, v in label_mapping.items():\n",
    "          if k == i:\n",
    "            lstm_top3_list.append(v)\n",
    "\n",
    "    #w2 = 1\n",
    "    lstm_top3_dict = {lstm_top3_list[0]:3, lstm_top3_list[1]:2, lstm_top3_list[2]:1}\n",
    "    #lstm_top3_dict_w = { k : v*w2 for k, v in lstm_top3_dict.items() }\n",
    "\n",
    "    ## 유사도 코드 적용\n",
    "    # 입력값 전처리\n",
    "    input_document = remove_punctuation(description)\n",
    "    input_tokens = word_tokenize(input_document.lower())  # 소문자로 변환 및 토큰화\n",
    "    input_tokens = [lemmatizer.lemmatize(word) for word in input_tokens if word not in stop_words]\n",
    "\n",
    "    documents = list(cosine_dict.values())\n",
    "    documents.append(' '.join(input_tokens))\n",
    "    \n",
    "    tfidf_matrix = tfidf.transform(documents)\n",
    "\n",
    "     # 입력 설명서와 각 HS 코드 간의 코사인 유사도 계산\n",
    "    similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "\n",
    "    # 유사도가 가장 높은 상위 3개 HS 코드 인덱스 및 값\n",
    "    most_similar_hs_code_indices = np.argsort(similarities)[0][-3:][::-1]  # 상위 3개 인덱스\n",
    "    similarities_top3_list = [list(cosine_dict.keys())[i] for i in most_similar_hs_code_indices]  # 상위 3개 HS 코드\n",
    "\n",
    "    #w3 = 1\n",
    "    similarities_top3_dict = {similarities_top3_list[0]:3, similarities_top3_list[1]:2, similarities_top3_list[2]:1}\n",
    "    #similarities_top3_dict_w = { k : v*w3 for k, v in similarities_top3_dict.items() }\n",
    "    \n",
    "    ## 딕셔너리 병합 및 값 더하기\n",
    "    merged_dict = {}\n",
    "    for d in [lsvc_top3_dict, lstm_top3_dict, similarities_top3_dict]:\n",
    "        for k, v in d.items():\n",
    "            merged_dict[k] = merged_dict.get(k, 0) + v\n",
    "    \n",
    "    # 상위 3개 HS 코드 가져오기\n",
    "    top_3_hs_codes = dict(sorted(merged_dict.items(), key=lambda x: x[1], reverse=True)[:3])\n",
    "    \n",
    "    return list(top_3_hs_codes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a0dda-c297-4b44-90ad-fb21dcde20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "three_ensemble_predict('Optical wireless mouse - three push button switches, scroll wheel, laser sensor, transmitter and Bluetooth transmitter in a plastic casing with a USB connection (dimensions: 106 x 57 x 35 mm), (Figure attached) - for entry of position data and to trigger Control commands, - to the central unit of automatic data processing machines directly connected and able to provide data in a system-usable form - together with accessory pack (user manual, 2 AAA rechargeable batteries and USB charge cable) in a joint Verkaufsumschließung. The optical mouse determines the character of the whole. \"input device for automatic data processing machines, no keyboard, not intended for use in civil aircraft - optical computer mouse in the set with no charakterbestimmendem pack.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9978d-d225-44d7-bbc9-fe83ac69378d",
   "metadata": {},
   "source": [
    "# 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d937b0-fe7c-4c0b-87b5-65906169f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_excel('./최종 파일/전처리완료된통합검증데이터.xlsx', index_col = 0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c505d2-0abd-40a7-80ab-cce741e9c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf933f6-07fc-4598-b830-0a54dbefa51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['hs code'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e81ca-51c3-4ec2-b9eb-2c84f1282a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "cnt_top = 0\n",
    "for i, v in zip(test['hs code'], test['name_des']):\n",
    "    result = three_ensemble_predict(v)\n",
    "    if i in result:\n",
    "        cnt += 1 \n",
    "    if i == result[0]:\n",
    "        cnt_top += 1\n",
    "        \n",
    "print(cnt)\n",
    "print(cnt/len(test))\n",
    "\n",
    "print(cnt_top)\n",
    "print(cnt_top/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda43e8-af6e-42ca-9d18-8564248f2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_test1 = pd.read_excel('84미국사례 테스트용.xlsx', index_col=0)\n",
    "usa_test2 = pd.read_excel('85미국사례 테스트용.xlsx', index_col=0)\n",
    "\n",
    "usa_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f3833-9af7-4582-88c3-84e3c1faf972",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ef7bb-5a85-4c86-9c43-c95ff9e6b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_test = pd.concat([usa_test1, usa_test2])\n",
    "usa_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a4d4d-52e9-45b3-9ff9-40edf3ed7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_test.reset_index(inplace=True)\n",
    "usa_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde0c4b-17f5-4430-a4ea-9c3ea95a2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07373d-80b0-455c-8959-d9b67dbf7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_test.to_excel('미국사례테스트용.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9eec1e-b7c5-47a3-8dd3-96049624b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "cnt_top = 0\n",
    "for i, v in zip(usa_test['hs code'], usa_test['description']):\n",
    "    pred = three_ensemble_predict(v)\n",
    "    if i in pred:\n",
    "        cnt += 1 \n",
    "    if i == pred[0]:\n",
    "        cnt_top += 1\n",
    "\n",
    "print('<세가지 모델 합친 것 미국사례 정확도>')\n",
    "print('3개중 하나 맞춘 개수:', cnt)\n",
    "print('3개중 하나 맞춘 정확도:', cnt/len(usa_test))\n",
    "\n",
    "print('top1 맞춘 개수:', cnt_top)\n",
    "print('top1 맞춘 개수:', cnt_top/len(usa_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34ffda-1cae-4331-9450-5b1bb7eaa386",
   "metadata": {},
   "source": [
    "# 미국 사례 테스트 - 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090a57b-3a7c-4fec-bb68-4feca17746f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_total = pd.read_excel('미국테스트전체데이터.xlsx', index_col=0)\n",
    "usa_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed6a81-8e7d-4c88-aac9-93b0c1cf6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_total.reset_index(drop=True, inplace=True)\n",
    "usa_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7fcda-a1b2-4095-9dd8-cecaa553970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "cnt_top = 0\n",
    "for i, v in zip(usa_total['hs code'], usa_total['description']):\n",
    "    pred = three_ensemble_predict(v)\n",
    "    if i in pred:\n",
    "        cnt += 1 \n",
    "    if i == pred[0]:\n",
    "        cnt_top += 1\n",
    "\n",
    "print('<세가지 모델 합친 것 미국사례 정확도>')\n",
    "print('3개중 하나 맞춘 개수:', cnt)\n",
    "print('3개중 하나 맞춘 정확도:', round(cnt/len(usa_total),3))\n",
    "\n",
    "print('top1 맞춘 개수:', cnt_top)\n",
    "print('top1 맞춘 개수:', round(cnt_top/len(usa_total),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
